{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_s7s84HEO9tV"
   },
   "outputs": [],
   "source": [
    "#on importe les bibliotheques que l'on aura besoin\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8HrE_mgJPaX3"
   },
   "outputs": [],
   "source": [
    "def process(data, standardize):\n",
    "    sequences= data[:,0]\n",
    "    mfe=data[:,1].astype(float)\n",
    "    struct=data[:,2]\n",
    "    hairpins= data[:,3].astype(int)\n",
    "\n",
    "    # On encode les nucleotides et les secondary struct\n",
    "    nuc = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    brack = {'(': 0, '.': 1, ')': 2}\n",
    "\n",
    "    # Determine les longues maximales\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    max_struc = max(len(struc) for struc in struct)\n",
    "\n",
    "    # On initialize les pads pour les differentes variables\n",
    "    pad_seq = np.zeros((len(sequences), max_len, 4))\n",
    "    pad_struct = np.zeros((len(struct), max_struc, 3))\n",
    "    pad_hairpins = np.zeros((len(hairpins), 5))  # Assuming hairpins range from 1 to 5\n",
    "\n",
    "    # One-hot encode les sequences\n",
    "    for i, seq in enumerate(sequences):\n",
    "        for j, ch in enumerate(seq):\n",
    "            pad_seq[i, j, nuc[ch]] = 1\n",
    "\n",
    "    # One-hot encode les structures\n",
    "    for i, struc in enumerate(struct):\n",
    "        for j, ch in enumerate(struc):\n",
    "            pad_struct[i, j, brack[ch]] =1\n",
    "\n",
    "        # One-hot encode les hairpins\n",
    "    for i, hp in enumerate(hairpins):\n",
    "        pad_hairpins[i, hp-1] = 1\n",
    "\n",
    "    # on standardize les donnees\n",
    "    if standardize:\n",
    "        mfe = (mfe - np.mean(mfe)) / np.std(mfe)\n",
    "\n",
    "    return pad_seq, mfe, pad_struct, pad_hairpins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "F9b1dbhPPfLI"
   },
   "outputs": [],
   "source": [
    "# dans le tableau suivant je definit un tableau avec\n",
    "#les noms des dossiers que l'on va importer pour l'analyse\n",
    "files=['test_2p5M_struct.pkl','train_2p5M_struct.pkl','valid_2p5M_struct.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wFZMJ26yPpO3"
   },
   "outputs": [],
   "source": [
    "# on definit nos datasets\n",
    "test=[]\n",
    "train=[]\n",
    "valid=[]\n",
    "for i in range(len(files)):\n",
    "    with open(files[i],'rb') as f:\n",
    "        data= pickle.load(f)\n",
    "    if i==0:\n",
    "        test=np.array(data)\n",
    "    elif i ==1:\n",
    "        train= np.array(data)\n",
    "    else:\n",
    "        valid= np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e60cW20wPsa6"
   },
   "outputs": [],
   "source": [
    "# on definit nos variables pour chaque split\n",
    "seq_train, mfe_train, struct_train, pins_train= process(train,True)\n",
    "seq_valid, mfe_valid, struct_valid, pins_valid= process(valid,True)\n",
    "seq_test, mfe_test, struct_test, pins_test= process(test,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ne9CDqNaRdTq"
   },
   "outputs": [],
   "source": [
    "# on definit nos tensors\n",
    "#sequences\n",
    "seq_train= torch.tensor(seq_train, dtype= torch.float32)\n",
    "seq_valid= torch.tensor(seq_valid, dtype= torch.float32)\n",
    "seq_test= torch.tensor(seq_test, dtype= torch.float32)\n",
    "\n",
    "#MFE\n",
    "mfe_train= torch.tensor(mfe_train, dtype= torch.float32)\n",
    "mfe_valid= torch.tensor(mfe_valid, dtype= torch.float32)\n",
    "mfe_test= torch.tensor(mfe_test, dtype= torch.float32)\n",
    "\n",
    "#hairpins\n",
    "pins_train = torch.tensor(pins_train, dtype=torch.int64)\n",
    "pins_valid = torch.tensor(pins_valid, dtype=torch.int64)\n",
    "pins_test = torch.tensor(pins_test, dtype=torch.int64)\n",
    "\n",
    "#Struct\n",
    "struct_train= torch.tensor(struct_train, dtype= torch.float32)\n",
    "struct_valid= torch.tensor(struct_valid, dtype= torch.float32)\n",
    "struct_test= torch.tensor(struct_test, dtype= torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RsmaxH_4SR37"
   },
   "outputs": [],
   "source": [
    "# on redefinit nos splits\n",
    "# train dataset\n",
    "train_set= TensorDataset(seq_train, struct_train,mfe_train, pins_train)\n",
    "train_loader= DataLoader(train_set, batch_size=32, shuffle= True)\n",
    "# validation set\n",
    "valid_set= TensorDataset(seq_valid, struct_valid,mfe_valid, pins_valid)\n",
    "valid_loader= DataLoader(valid_set, batch_size=32)\n",
    "#test set\n",
    "test_set= TensorDataset(seq_test, struct_test,mfe_test, pins_test)\n",
    "test_loader= DataLoader(test_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_XeG7FCwXSui"
   },
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "  def __init__(self, input_size_seq, input_size_struct, hidden_size, output_size_mfe, input_size_hairpins, hidden_size_hairpins, output_size_hairpins):\n",
    "    super(GRUModel, self).__init__()\n",
    "    self.gru = nn.GRU(input_size=input_size_seq, hidden_size=hidden_size, batch_first=True)\n",
    "\n",
    "    # on ajuste pour mfe\n",
    "    self.fc_mfe = nn.Linear(1, output_size_mfe)  # Assumons un feature pour mfe\n",
    "\n",
    "    self.fc_hairpins1 = nn.Linear(input_size_hairpins, hidden_size_hairpins)\n",
    "\n",
    "\n",
    "    self.fc_hairpins2 = nn.Linear(hidden_size + output_size_mfe + hidden_size_hairpins, output_size_hairpins)\n",
    "    #self.fc_struct = nn.Linear(hidden_size, 64)\n",
    "    #self.fc_struct = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    print(f\"self.fc_hairpins2 ={self.fc_hairpins2}\")\n",
    "    print(f\"self.fc_hairpins1= {self.fc_hairpins1}\")\n",
    "    print(f\"self.gru={self.gru}\")\n",
    "    print(f\"self.fc_mfe= {self.fc_mfe}\")\n",
    "\n",
    "  def forward(self, seq_input, struct_input, mfe_input, hairpins_input):\n",
    "    gru_output, _ = self.gru(seq_input)\n",
    "    batch_size = gru_output.size(0)\n",
    "\n",
    "    # On reshape le data mfe si necessaire\n",
    "    if len(mfe_input.size()) == 1:  # si le mfe a seulement une dimension\n",
    "      mfe_input = mfe_input.view(batch_size, 1)  # Reshape(batch_size, 1)\n",
    "\n",
    "    # on handle le input\n",
    "    hairpins_processed = self.fc_hairpins1(hairpins_input)\n",
    "    hairpins_processed = nn.functional.relu(hairpins_processed)  # activation optionnel peut overfit\n",
    "\n",
    "    # concat avec le dernier timestep de la sortie Gru\n",
    "    concatenated = torch.cat((gru_output[:, -1, :], mfe_input, hairpins_processed), dim=1)\n",
    "\n",
    "    # s'assure que Mfe a les bonnes dimensions\n",
    "    self.fc_mfe = nn.Linear(129, 1)  # on assuime 129 features base surles analyses precedentes\n",
    "\n",
    "    hairpins_output = self.fc_hairpins2(concatenated)\n",
    "    mfe_output = self.fc_mfe(concatenated)  # on utilise le nouveau mfe reshaped\n",
    "    # prediction structure secondaire\n",
    "    #struct_output = self.fc_struct(gru_output)  # Apply FC to entire sequence output\n",
    "\n",
    "   # Reshape to match target format\n",
    "    #struct_output = struct_output.reshape(struct_output.size(0), -1, self.fc_struct.out_features)\n",
    "\n",
    "    #print(f\"mfe_output= {mfe_output.shape}\")\n",
    "    #print(f\"hairpins_output= {hairpins_output.shape}\")\n",
    "\n",
    "    return mfe_output, hairpins_output #, struct_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jXTHeJfwXdrB",
    "outputId": "5bb06ec9-3678-4602-85a9-30226003dd85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.fc_hairpins2 =Linear(in_features=129, out_features=5, bias=True)\n",
      "self.fc_hairpins1= Linear(in_features=5, out_features=64, bias=True)\n",
      "self.gru=GRU(4, 64, batch_first=True)\n",
      "self.fc_mfe= Linear(in_features=1, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# on instancie le modele avec les pertes\n",
    "model =GRUModel(4,3,64,1,5,64,5)\n",
    "criterion_mfe= nn.MSELoss()\n",
    "criterion_pins= nn.CrossEntropyLoss()\n",
    "criterion_struct=nn.CrossEntropyLoss()\n",
    "optimizer= optim.Adam(model.parameters(),lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "id": "0p9IKkCnXjBo",
    "outputId": "db13b6f5-e77f-42df-d26b-1ae9665f93e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train MFE Loss: 1.0073478120, Train Hairpins Loss: 0.0020567416, Train struct Loss: epoch_loss_struct:.10f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Valid MFE Loss: 1.0058134710, Valid Hairpins Loss: 0.0000275761 Valid struct Loss: valid_loss_struct:.10f\n",
      "Test MFE Loss: 1.0056267150, Test Hairpins Loss: 0.0000179889, test Hairpins Loss: test_loss_struct:.10f\n",
      "Epoch 2/20, Train MFE Loss: 1.0055711255, Train Hairpins Loss: 0.0000105815, Train struct Loss: epoch_loss_struct:.10f\n",
      "Epoch 2/20, Valid MFE Loss: 1.0053697120, Valid Hairpins Loss: 0.0000087013 Valid struct Loss: valid_loss_struct:.10f\n",
      "Test MFE Loss: 1.0050846651, Test Hairpins Loss: 0.0000084690, test Hairpins Loss: test_loss_struct:.10f\n",
      "Epoch 3/20, Train MFE Loss: 1.0053209328, Train Hairpins Loss: 0.0000038603, Train struct Loss: epoch_loss_struct:.10f\n",
      "Epoch 3/20, Valid MFE Loss: 1.0056391748, Valid Hairpins Loss: 0.0000014379 Valid struct Loss: valid_loss_struct:.10f\n",
      "Test MFE Loss: 1.0052092616, Test Hairpins Loss: 0.0000014237, test Hairpins Loss: test_loss_struct:.10f\n",
      "Epoch 4/20, Train MFE Loss: 1.0053265739, Train Hairpins Loss: 0.0000026407, Train struct Loss: epoch_loss_struct:.10f\n",
      "Epoch 4/20, Valid MFE Loss: 1.0053274922, Valid Hairpins Loss: 0.0000005292 Valid struct Loss: valid_loss_struct:.10f\n",
      "Test MFE Loss: 1.0055653593, Test Hairpins Loss: 0.0000004807, test Hairpins Loss: test_loss_struct:.10f\n",
      "Epoch 5/20, Train MFE Loss: 1.0053170649, Train Hairpins Loss: 0.0000022540, Train struct Loss: epoch_loss_struct:.10f\n",
      "Epoch 5/20, Valid MFE Loss: 1.0053178818, Valid Hairpins Loss: 0.0000004981 Valid struct Loss: valid_loss_struct:.10f\n",
      "Test MFE Loss: 1.0051971292, Test Hairpins Loss: 0.0000004850, test Hairpins Loss: test_loss_struct:.10f\n",
      "Epoch 6/20, Train MFE Loss: 1.0052930241, Train Hairpins Loss: 0.0000017242, Train struct Loss: epoch_loss_struct:.10f\n",
      "Epoch 6/20, Valid MFE Loss: 1.0050769969, Valid Hairpins Loss: 0.0000015930 Valid struct Loss: valid_loss_struct:.10f\n",
      "Test MFE Loss: 1.0051713560, Test Hairpins Loss: 0.0000015901, test Hairpins Loss: test_loss_struct:.10f\n",
      "Epoch 7/20, Train MFE Loss: 1.0052965900, Train Hairpins Loss: 0.0000012697, Train struct Loss: epoch_loss_struct:.10f\n",
      "Epoch 7/20, Valid MFE Loss: 1.0053722002, Valid Hairpins Loss: 0.0000002295 Valid struct Loss: valid_loss_struct:.10f\n",
      "Test MFE Loss: 1.0052938997, Test Hairpins Loss: 0.0000002230, test Hairpins Loss: test_loss_struct:.10f\n",
      "Epoch 8/20, Train MFE Loss: 1.0052424678, Train Hairpins Loss: 0.0000011596, Train struct Loss: epoch_loss_struct:.10f\n",
      "Epoch 8/20, Valid MFE Loss: 1.0055180424, Valid Hairpins Loss: 0.0000001581 Valid struct Loss: valid_loss_struct:.10f\n",
      "Test MFE Loss: 1.0049021267, Test Hairpins Loss: 0.0000001574, test Hairpins Loss: test_loss_struct:.10f\n",
      "Epoch 9/20, Train MFE Loss: 1.0053550461, Train Hairpins Loss: 0.0000010297, Train struct Loss: epoch_loss_struct:.10f\n",
      "Epoch 9/20, Valid MFE Loss: 1.0054101617, Valid Hairpins Loss: 0.0000037765 Valid struct Loss: valid_loss_struct:.10f\n",
      "Test MFE Loss: 1.0055121754, Test Hairpins Loss: 0.0000038004, test Hairpins Loss: test_loss_struct:.10f\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ce3bac323c1a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_mfe\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_hairpins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# boucle d'entrainement\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss_mfe = 0.0\n",
    "    running_loss_hairpins = 0.0\n",
    "    #running_loss_struct=0.0\n",
    "\n",
    "    for seq_batch, struct_batch, mfe_batch, hairpins_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        #print(f\"seq_batch= {seq_batch.shape}\")\n",
    "        #print(f\"struct_batch= {struct_batch.shape}\")\n",
    "        #print(f\"mfe= {mfe_batch.shape}\")\n",
    "        #print(f\"hairpins_batch= {hairpins_batch.shape}\")\n",
    "\n",
    "        hairpins_batch = hairpins_batch.float()\n",
    "        mfe_pred, hairpins_pred = model(seq_batch, struct_batch, mfe_batch, hairpins_batch)\n",
    "\n",
    "        loss_mfe = criterion_mfe(mfe_pred, mfe_batch)\n",
    "        loss_hairpins = criterion_pins(hairpins_pred, hairpins_batch.squeeze().float())\n",
    "        #print(f\"struct_pred: {struct_pred.shape } struct_batch={struct_batch.shape}\")\n",
    "        #loss_struct= criterion_struct(struct_pred, struct_batch)\n",
    "        loss = loss_mfe + loss_hairpins\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss_mfe += loss_mfe.item() * seq_batch.size(0)\n",
    "        running_loss_hairpins += loss_hairpins.item() * seq_batch.size(0)\n",
    "        #running_loss_struct += loss_struct.item() * seq_batch.size(0)\n",
    "\n",
    "    epoch_loss_mfe = running_loss_mfe / len(train_set)\n",
    "    epoch_loss_hairpins = running_loss_hairpins / len(train_set)\n",
    "    #epoch_loss_struct = running_loss_struct / len(train_set)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train MFE Loss: {epoch_loss_mfe:.10f}, Train Hairpins Loss: {epoch_loss_hairpins:.10f}, Train struct Loss: epoch_loss_struct:.10f\")\n",
    "    # boucle de validation\n",
    "    model.eval()\n",
    "    valid_loss_mfe = 0.0\n",
    "    valid_loss_hairpins = 0.0\n",
    "    #valid_loss_struct=0.0\n",
    "    with torch.no_grad():\n",
    "        for seq_batch, struct_batch, mfe_batch, hairpins_batch in valid_loader:\n",
    "            hairpins_batch = hairpins_batch.float()\n",
    "            mfe_pred, hairpins_pred = model(seq_batch, struct_batch, mfe_batch, hairpins_batch)\n",
    "            valid_loss_mfe += criterion_mfe(mfe_pred, mfe_batch).item() * seq_batch.size(0)\n",
    "            valid_loss_hairpins += criterion_pins(hairpins_pred, hairpins_batch.squeeze().float()).item() * seq_batch.size(0)\n",
    "            #valid_loss_struct += criterion_struct(struct_pred, struct_batch).item() * seq_batch.size(0)\n",
    "\n",
    "    valid_loss_mfe /= len(valid_set)\n",
    "    valid_loss_hairpins /= len(valid_set)\n",
    "    #valid_loss_struct /= len(valid_set)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Valid MFE Loss: {valid_loss_mfe:.10f}, Valid Hairpins Loss: {valid_loss_hairpins:.10f} Valid struct Loss: valid_loss_struct:.10f\")\n",
    "    # Evaluation pour le test set\n",
    "    model.eval()\n",
    "    test_loss_mfe = 0.0\n",
    "    test_loss_hairpins = 0.0\n",
    "    #test_loss_struct=0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "       for seq_batch, struct_batch, mfe_batch, hairpins_batch in test_loader:\n",
    "           hairpins_batch = hairpins_batch.float()\n",
    "           mfe_pred, hairpins_pred = model(seq_batch, struct_batch, mfe_batch, hairpins_batch)\n",
    "           test_loss_mfe += criterion_mfe(mfe_pred, mfe_batch).item() * seq_batch.size(0)\n",
    "           test_loss_hairpins += criterion_pins(hairpins_pred, hairpins_batch.squeeze().float()).item() * seq_batch.size(0)\n",
    "          # test_loss_struct += criterion_struct(struct_pred, struct_batch).item() * seq_batch.size(0)\n",
    "\n",
    "    test_loss_mfe /= len(test_set)\n",
    "    test_loss_hairpins /= len(test_set)\n",
    "   # test_loss_struct /= len(test_set)\n",
    "\n",
    "    print(f\"Test MFE Loss: {test_loss_mfe:.10f}, Test Hairpins Loss: {test_loss_hairpins:.10f}, test Hairpins Loss: test_loss_struct:.10f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6kkrc0oTz0OJ"
   },
   "outputs": [],
   "source": [
    "#On sauve le modele\n",
    "torch.save(model.state_dict(), 'model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
