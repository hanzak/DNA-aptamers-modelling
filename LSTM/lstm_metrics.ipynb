{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5b6e5150",
      "metadata": {
        "id": "5b6e5150"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Bidirectional, Input\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from keras.losses import categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "02e86146",
      "metadata": {
        "id": "02e86146"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "path = 'train_2p5M_struct.pkl'\n",
        "with open(path, 'rb') as f:\n",
        "    data_train = pickle.load(f).dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "08fee287",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08fee287",
        "outputId": "0bd48f41-19ef-457d-b210-175101cb5d25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Extract sequences and energies\n",
        "sequences_train, energies_train, struct_train, hairpins_train = zip(*data_train)\n",
        "\n",
        "\n",
        "# Free memory\n",
        "del data_train\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "46a7ab55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46a7ab55",
        "outputId": "ec23df5d-f7f3-4667-9245-fe4cd3ab8bbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Convert sequences to n grams\n",
        "def seq2ngrams(seqs, n=1):\n",
        "    return np.array([[seq[i:i+n] for i in range(len(seq))] for seq in seqs], dtype=object)\n",
        "\n",
        "maxlen_seq = 50\n",
        "input_grams_train = seq2ngrams(sequences_train)\n",
        "\n",
        "# Free memory\n",
        "del sequences_train\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f5dc96a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5dc96a1",
        "outputId": "91b5d388-1b3e-475c-bd49-d4d5b6625501"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Prepare for embedding\n",
        "tokenizer_encoder = Tokenizer()\n",
        "tokenizer_encoder.fit_on_texts(input_grams_train)\n",
        "input_data_train = tokenizer_encoder.texts_to_sequences(input_grams_train)\n",
        "input_data_train = pad_sequences(input_data_train, maxlen=maxlen_seq, padding='post')\n",
        "n_words = len(tokenizer_encoder.word_index) + 1\n",
        "\n",
        "tokenizer_decoder = Tokenizer(char_level=True)\n",
        "tokenizer_decoder.fit_on_texts(struct_train)\n",
        "struct_train = tokenizer_decoder.texts_to_sequences(struct_train)\n",
        "struct_train = pad_sequences(struct_train, maxlen=maxlen_seq, padding='post')\n",
        "struct_train = to_categorical(struct_train)\n",
        "\n",
        "\n",
        "# Free memory\n",
        "del input_grams_train\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d70839a0",
      "metadata": {
        "id": "d70839a0"
      },
      "outputs": [],
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "def weighted_categorical_crossentropy(y_true, y_pred):\n",
        "    class_weights = tf.constant([1.0, 1.0, 2.0, 2.0])\n",
        "    weights = tf.reduce_sum(class_weights * y_true, axis=-1)\n",
        "    unweighted_loss = categorical_crossentropy(y_true, y_pred)\n",
        "    weighted_loss = unweighted_loss * weights\n",
        "    return weighted_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load both models\n",
        "full = tf.keras.models.load_model('full_2p5M.keras')\n",
        "partial = tf.keras.models.load_model('partial_2p5M.keras')"
      ],
      "metadata": {
        "id": "6qb07irg9I2N"
      },
      "id": "6qb07irg9I2N",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data\n",
        "path = 'data_test.pkl'\n",
        "with open(path, 'rb') as f:\n",
        "    test = pickle.load(f)"
      ],
      "metadata": {
        "id": "Ks2P-EWa0o08"
      },
      "id": "Ks2P-EWa0o08",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_test, energies_test, struct_test, hairpins_test = zip(*test)\n",
        "\n",
        "input_grams_test = seq2ngrams(sequences_test)\n",
        "\n",
        "input_data_test = tokenizer_encoder.texts_to_sequences(input_grams_test)\n",
        "input_data_test = pad_sequences(input_data_test, maxlen=maxlen_seq, padding='post')\n",
        "\n",
        "struct_test = tokenizer_decoder.texts_to_sequences(struct_test)\n",
        "struct_test = pad_sequences(struct_test, maxlen=maxlen_seq, padding='post')\n",
        "struct_test = to_categorical(struct_test)\n",
        "\n",
        "energies_test = np.asarray(energies_test)\n",
        "hairpins_test = np.asarray(hairpins_test)"
      ],
      "metadata": {
        "id": "8qPuZnwA2rVx"
      },
      "id": "8qPuZnwA2rVx",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_10_20 = []\n",
        "int_21_30 = []\n",
        "int_31_40 = []\n",
        "int_41_50 = []\n",
        "int_full = []\n",
        "\n",
        "for i in test:\n",
        "  seq_len = len(i[0])\n",
        "\n",
        "  if seq_len >= 10 and seq_len <= 50:\n",
        "    int_full.append(i)\n",
        "  if seq_len >= 10 and seq_len <= 20:\n",
        "    int_10_20.append(i)\n",
        "  elif seq_len >= 21 and seq_len <= 30:\n",
        "    int_21_30.append(i)\n",
        "  elif seq_len >= 31 and seq_len <= 40:\n",
        "    int_31_40.append(i)\n",
        "  elif seq_len >= 41 and seq_len <= 50:\n",
        "    int_41_50.append(i)"
      ],
      "metadata": {
        "id": "CV9_fVZv4zBE"
      },
      "id": "CV9_fVZv4zBE",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for each interval for the (mfe, hairpins) model\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "for interval in [int_10_20, int_21_30, int_31_40, int_41_50, int_full]:\n",
        "  print(f\"Evaluating base model for interval with seq_len: {len(interval[0][0])} to {len(interval[-1][0])}\")\n",
        "  sequences_test, energies_test, struct_test, hairpins_test = zip(*interval)\n",
        "\n",
        "  input_grams_test = seq2ngrams(sequences_test)\n",
        "\n",
        "  input_data_test = tokenizer_encoder.texts_to_sequences(input_grams_test)\n",
        "  input_data_test = pad_sequences(input_data_test, maxlen=maxlen_seq, padding='post')\n",
        "\n",
        "  energies_test = np.asarray(energies_test)\n",
        "  hairpins_test = np.asarray(hairpins_test)\n",
        "\n",
        "  partial.evaluate(input_data_test, [energies_test, hairpins_test])\n",
        "\n",
        "  pred = partial.predict(input_data_test)\n",
        "  energies_pred = pred[0]\n",
        "  hairpins_pred = pred[1]\n",
        "\n",
        "  print(f'R2 for mfe: {r2_score(energies_test, energies_pred)}')\n",
        "  print(f'R2 for hairpins: {r2_score(hairpins_test, hairpins_pred)}')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzeVmOSe6Yw4",
        "outputId": "2cee701a-0f72-4375-963d-905ea534c599"
      },
      "id": "vzeVmOSe6Yw4",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating base model for interval with seq_len: 10 to 20\n",
            "172/172 [==============================] - 62s 312ms/step - loss: 0.0172 - MFE_loss: 0.0110 - Hairpins_loss: 0.0031\n",
            "[0.017188794910907745, 0.010999493300914764, 0.003094649640843272]\n",
            "172/172 [==============================] - 55s 316ms/step\n",
            "R2 for mfe: 0.9861970262933883\n",
            "R2 for hairpins: 0.8077363912507864\n",
            "\n",
            "Evaluating base model for interval with seq_len: 21 to 30\n",
            "157/157 [==============================] - 47s 300ms/step - loss: 0.1425 - MFE_loss: 0.0727 - Hairpins_loss: 0.0349\n",
            "[0.14254246652126312, 0.07274679839611053, 0.034897830337285995]\n",
            "157/157 [==============================] - 49s 314ms/step\n",
            "R2 for mfe: 0.959739324079497\n",
            "R2 for hairpins: 0.7254995573309282\n",
            "\n",
            "Evaluating base model for interval with seq_len: 31 to 40\n",
            "157/157 [==============================] - 50s 316ms/step - loss: 0.4641 - MFE_loss: 0.2384 - Hairpins_loss: 0.1128\n",
            "[0.46406304836273193, 0.23843254148960114, 0.11281520873308182]\n",
            "157/157 [==============================] - 47s 300ms/step\n",
            "R2 for mfe: 0.918382870133471\n",
            "R2 for hairpins: 0.6115592280155933\n",
            "\n",
            "Evaluating base model for interval with seq_len: 41 to 50\n",
            "157/157 [==============================] - 49s 310ms/step - loss: 0.8718 - MFE_loss: 0.4573 - Hairpins_loss: 0.2072\n",
            "[0.87179034948349, 0.4573020935058594, 0.20724430680274963]\n",
            "157/157 [==============================] - 48s 308ms/step\n",
            "R2 for mfe: 0.8856760308519306\n",
            "R2 for hairpins: 0.5364090253350301\n",
            "\n",
            "Evaluating base model for interval with seq_len: 10 to 50\n",
            "641/641 [==============================] - 199s 311ms/step - loss: 0.3652 - MFE_loss: 0.1904 - Hairpins_loss: 0.0874\n",
            "[0.3651961386203766, 0.1903855800628662, 0.0874052420258522]\n",
            "641/641 [==============================] - 199s 310ms/step\n",
            "R2 for mfe: 0.9446985385703042\n",
            "R2 for hairpins: 0.7057608101780234\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for each interval for the (mfe, hairpins, structure) model\n",
        "from sklearn.metrics import classification_report\n",
        "class_labels = {key:value for key,value in tokenizer_decoder.word_index.items()}\n",
        "\n",
        "for interval in [int_10_20, int_21_30, int_31_40, int_41_50, int_full]:\n",
        "  print(f\"Evaluating full model for interval with seq_len: {len(interval[0][0])} to {len(interval[-1][0])}\")\n",
        "  sequences_test, energies_test, struct_test, hairpins_test = zip(*interval)\n",
        "\n",
        "  input_grams_test = seq2ngrams(sequences_test)\n",
        "\n",
        "  input_data_test = tokenizer_encoder.texts_to_sequences(input_grams_test)\n",
        "  input_data_test = pad_sequences(input_data_test, maxlen=maxlen_seq, padding='post')\n",
        "\n",
        "  struct_test = tokenizer_decoder.texts_to_sequences(struct_test)\n",
        "  struct_test = pad_sequences(struct_test, maxlen=maxlen_seq, padding='post')\n",
        "  struct_test = to_categorical(struct_test)\n",
        "\n",
        "  energies_test = np.asarray(energies_test)\n",
        "  hairpins_test = np.asarray(hairpins_test)\n",
        "  full.evaluate(input_data_test, [energies_test, hairpins_test, struct_test])\n",
        "\n",
        "  pred_seq = full.predict(input_data_test)[2]\n",
        "  max_indices_pred = np.argmax(pred_seq, axis=2)\n",
        "  max_indices_true = np.argmax(struct_test, axis=2)\n",
        "\n",
        "  y_pred_flat = max_indices_pred.ravel()\n",
        "  y_true_flat = max_indices_true.ravel()\n",
        "\n",
        "  # Mask padding\n",
        "  y_pred_flat_masked = y_pred_flat[y_pred_flat != 0]\n",
        "  y_true_flat_masked = y_true_flat[y_true_flat != 0]\n",
        "\n",
        "  report_dict = classification_report(y_true_flat_masked, y_pred_flat_masked, target_names=class_labels, output_dict=True)\n",
        "  print(report_dict)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxEZPtfqBF9v",
        "outputId": "88854810-f1cd-448a-cf27-e52593faf1a4"
      },
      "id": "JxEZPtfqBF9v",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating full model for interval with seq_len: 10 to 20\n",
            "172/172 [==============================] - 55s 317ms/step\n",
            "{'.': {'precision': 0.9943668361656679, 'recall': 0.9887781954887218, 'f1-score': 0.9915646412380656, 'support': 53200}, '(': {'precision': 0.9792455381287182, 'recall': 0.9887372013651877, 'f1-score': 0.9839684804021466, 'support': 14650}, ')': {'precision': 0.9794691699871683, 'recall': 0.9899658703071672, 'f1-score': 0.9846895474759819, 'support': 14650}, 'accuracy': 0.9889818181818182, 'macro avg': {'precision': 0.984360514760518, 'recall': 0.9891604223870255, 'f1-score': 0.986740889705398, 'support': 82500}, 'weighted avg': {'precision': 0.98903619585347, 'recall': 0.9889818181818182, 'f1-score': 0.9889948972397535, 'support': 82500}}\n",
            "\n",
            "Evaluating full model for interval with seq_len: 21 to 30\n",
            "157/157 [==============================] - 50s 320ms/step\n",
            "{'.': {'precision': 0.9758121670743696, 'recall': 0.9603122820437825, 'f1-score': 0.9680001814305802, 'support': 88894}, '(': {'precision': 0.9052710467149637, 'recall': 0.9386623840853753, 'f1-score': 0.9216643776387405, 'support': 19303}, ')': {'precision': 0.9044143378493226, 'recall': 0.9372118323576646, 'f1-score': 0.9205210400447769, 'support': 19303}, 'accuracy': 0.9535372549019607, 'macro avg': {'precision': 0.928499183879552, 'recall': 0.9453954994956074, 'f1-score': 0.9367285330380325, 'support': 127500}, 'weighted avg': {'precision': 0.9543231667306152, 'recall': 0.9535372549019607, 'f1-score': 0.953796966632431, 'support': 127500}}\n",
            "\n",
            "Evaluating full model for interval with seq_len: 31 to 40\n",
            "157/157 [==============================] - 50s 320ms/step\n",
            "{'.': {'precision': 0.9523392909219681, 'recall': 0.9295450479025358, 'f1-score': 0.9408041222687294, 'support': 122958}, '(': {'precision': 0.8361984626135569, 'recall': 0.8775622456088885, 'f1-score': 0.8563811704925659, 'support': 27271}, ')': {'precision': 0.829447427680582, 'recall': 0.8779289354992483, 'f1-score': 0.8529998574889555, 'support': 27271}, 'accuracy': 0.9136281690140845, 'macro avg': {'precision': 0.8726617270720357, 'recall': 0.895012076336891, 'f1-score': 0.883395050083417, 'support': 177500}, 'weighted avg': {'precision': 0.9156144428585623, 'recall': 0.9136281690140845, 'f1-score': 0.914343229746493, 'support': 177500}}\n",
            "\n",
            "Evaluating full model for interval with seq_len: 41 to 50\n",
            "157/157 [==============================] - 50s 317ms/step\n",
            "{'.': {'precision': 0.9278303161307755, 'recall': 0.8960649235426126, 'f1-score': 0.9116710030266022, 'support': 153288}, '(': {'precision': 0.7689545191993772, 'recall': 0.8251765213173071, 'f1-score': 0.7960740981475464, 'support': 37106}, ')': {'precision': 0.7718271486592164, 'recall': 0.8245566754702743, 'f1-score': 0.7973210679244791, 'support': 37106}, 'accuracy': 0.8728395604395605, 'macro avg': {'precision': 0.8228706613297897, 'recall': 0.848599373443398, 'f1-score': 0.8350220563662093, 'support': 227500}, 'weighted avg': {'precision': 0.8764725189741331, 'recall': 0.8728395604395605, 'f1-score': 0.8741659153591665, 'support': 227500}}\n",
            "\n",
            "Evaluating full model for interval with seq_len: 10 to 50\n",
            "641/641 [==============================] - 205s 319ms/step\n",
            "{'.': {'precision': 0.9539269117956704, 'recall': 0.9313477076062533, 'f1-score': 0.942502098507701, 'support': 418340}, '(': {'precision': 0.8441489258663774, 'recall': 0.8863520797315163, 'f1-score': 0.864735881255705, 'support': 98330}, ')': {'precision': 0.8433543691199814, 'recall': 0.8861181734974067, 'f1-score': 0.864207571685032, 'support': 98330}, 'accuracy': 0.9169219512195121, 'macro avg': {'precision': 0.8804767355940096, 'recall': 0.9012726536117254, 'f1-score': 0.8904818504828126, 'support': 615000}, 'weighted avg': {'precision': 0.9186959077668444, 'recall': 0.9169219512195121, 'f1-score': 0.9175501424672752, 'support': 615000}}\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}