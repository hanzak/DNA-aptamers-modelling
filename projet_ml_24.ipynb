{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WVyph1I3CrHW"
      },
      "outputs": [],
      "source": [
        "# %pip install scikit-learn\n",
        "#%pip install pandas torch torchvision torchaudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XYvscTx9PMjo"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Function to convert sequence to pairings\n",
        "# def convert_to_pairings(seq):\n",
        "\n",
        "#     # seq = seq[0]\n",
        "#     result = []\n",
        "\n",
        "#     AT_pair = []\n",
        "#     TA_pair = []\n",
        "#     CG_pair = []\n",
        "#     GC_pair = []\n",
        "#     unpaired = []\n",
        "\n",
        "#     for i in range(len(seq)):\n",
        "#         # base pairings\n",
        "#         AT_pair_row = [0] * len(seq)\n",
        "#         TA_pair_row = [0] * len(seq)\n",
        "#         CG_pair_row = [0] * len(seq)\n",
        "#         GC_pair_row = [0] * len(seq)\n",
        "#         unpaired_row = [1] * len(seq)\n",
        "\n",
        "#         for j in range(len(seq)):\n",
        "#             if (seq[i] == 'A' and seq[j] == 'T'):\n",
        "#                 AT_pair_row[j] = 1\n",
        "#                 unpaired_row[j] = 1\n",
        "#             elif (seq[i] == 'T' and seq[j] == 'A'):\n",
        "#                 TA_pair_row[j] = 1\n",
        "#                 unpaired_row[j] = 1\n",
        "#             elif (seq[i] == 'C' and seq[j] == 'G'):\n",
        "#                 CG_pair_row[j] = 1\n",
        "#                 unpaired_row[j] = 1\n",
        "#             elif (seq[i] == 'G' and seq[j] == 'C'):\n",
        "#                 GC_pair_row[j] = 1\n",
        "#                 unpaired_row[j] = 0\n",
        "\n",
        "#         AT_pair.append(AT_pair_row)\n",
        "#         TA_pair.append(TA_pair_row)\n",
        "#         CG_pair.append(CG_pair_row)\n",
        "#         GC_pair.append(GC_pair_row)\n",
        "#         unpaired.append(unpaired_row)\n",
        "\n",
        "#     result.append(AT_pair)\n",
        "#     result.append(TA_pair)\n",
        "#     result.append(CG_pair)\n",
        "#     result.append(GC_pair)\n",
        "#     result.append(unpaired)\n",
        "\n",
        "#     return np.array(result)\n",
        "\n",
        "# def convert_to_pairings_dataset(dataset):\n",
        "#     result = []\n",
        "#     for seq in dataset:\n",
        "#         result.append(convert_to_pairings(seq))\n",
        "#     return result\n",
        "\n",
        "\n",
        "# def structure_to_matrix(structure):\n",
        "#     length = len(structure)\n",
        "#     matrix = np.zeros((length, length))\n",
        "#     stack = []\n",
        "\n",
        "#     for i, symbol in enumerate(structure):\n",
        "#         if symbol == '(':\n",
        "#             stack.append(i)\n",
        "#         elif symbol == ')':\n",
        "#             j = stack.pop()\n",
        "#             matrix[i][j] = 1\n",
        "#             matrix[j][i] = 1\n",
        "\n",
        "#     return matrix\n",
        "\n",
        "# def pad_structure(matrix, common_size, num_channels=None):\n",
        "#     if num_channels:\n",
        "#         padded_matrix = np.zeros((num_channels, *common_size))\n",
        "#         for i in range(num_channels):\n",
        "#             padded_matrix[i, :matrix.shape[1], :matrix.shape[2]] = matrix[i]\n",
        "#     else:\n",
        "#         padded_matrix = np.zeros(common_size)\n",
        "#         padded_matrix[:matrix.shape[0], :matrix.shape[1]] = matrix\n",
        "#     return padded_matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0IDPrGkjCrHZ"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# # Load the .pkl file\n",
        "# file_path = 'train_250k_struct.pkl'\n",
        "# data = pd.read_pickle(file_path)\n",
        "\n",
        "# subset = data.dataset[:100000]\n",
        "\n",
        "# # Assuming 'data' is a list of tuples with the format: (sequence, numerical value, structure string, other info)\n",
        "# # Extract sequences and numerical values as separate lists\n",
        "\n",
        "# dataset_X = np.array([item[0] for item in subset])  # Sequences\n",
        "# dataset_Y =  np.array([item[1] for item in subset])  # Numerical values\n",
        "# structures =  [structure_to_matrix(item[2]) for item in subset]  # Structural strings\n",
        "\n",
        "# # Convert dataset_X to pairings\n",
        "# dataset_X = convert_to_pairings_dataset(dataset_X)\n",
        "\n",
        "# # Convert dataset_X and dataset_Y into numpy arrays if not already\n",
        "# dataset_X = dataset_X\n",
        "# dataset_Y = np.array(dataset_Y, dtype=float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4kBu27oe4FgS"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# # data = pd.read_pickle('test_5M_struct.pkl')\n",
        "# data = pd.read_pickle('data_1p5M_struct.pkl')\n",
        "\n",
        "# print(data[0] , data[0][0],data[0][1],data[0][2])\n",
        "# print(structure_to_matrix(data[0][2]))\n",
        "# print(len(data) // 100000 + (1 if len(data) % 100000 != 0 else 0))\n",
        "# print(type(data))\n",
        "# print(type(data[0]))\n",
        "\n",
        "# data2 = pd.read_pickle('train_5M_struct.pkl')\n",
        "\n",
        "# print(data2[0] , data2[0][0],data2[0][1],data2[0][2])\n",
        "# print(structure_to_matrix(data2[0][2]))\n",
        "# print(len(data2) // 100000 + (1 if len(data2) % 100000 != 0 else 0))\n",
        "# print(len(data2))\n",
        "# print(type(data2))\n",
        "# print(type(data2[0]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qz3FJYVzCzke"
      },
      "outputs": [],
      "source": [
        "# print(max([len(seq[0]) for seq in data2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kSUmlXVI_C0S"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "\n",
        "# import torch\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# # Function to load data\n",
        "# def load_data(file_path):\n",
        "#     return pd.read_pickle(file_path)\n",
        "\n",
        "# # Function to preprocess and convert sequences and structures\n",
        "# def preprocess_and_convert(batch, common_size=(60, 60)):\n",
        "\n",
        "\n",
        "#     # Convert sequences to pairings\n",
        "#     # dataset_X = [convert_to_pairings(seq[0]) for seq in batch]\n",
        "#     # dataset_Y = [seq[1] for seq in batch]  # Assuming second element is the label\n",
        "#     # structures = [structure_to_matrix(seq[2]) for seq in batch]  # Assuming third element is the structure\n",
        "\n",
        "#     dataset_X = [convert_to_pairings(seq) for seq in batch[0]]\n",
        "#     dataset_Y = [seq for seq in batch[1]]  # Assuming second element is the label\n",
        "#     structures = [structure_to_matrix(seq) for seq in batch[2]]  # Assuming third element is the structure\n",
        "\n",
        "\n",
        "#     # Pad sequences and structures\n",
        "#     X_padded = [pad_structure(x, common_size, num_channels=5) for x in dataset_X]\n",
        "#     Y_padded = [pad_structure(y, common_size) for y in structures]  # Pad structures if they are labels\n",
        "\n",
        "#     return X_padded, Y_padded  # Return padded features and labels\n",
        "\n",
        "# # Function to save features and labels to a file\n",
        "# def save_batch(features, labels, batch_index, output_dir):\n",
        "#     batch_file = os.path.join(output_dir, f'batch_{batch_index}.npz')\n",
        "#     np.savez_compressed(batch_file, features=features, labels=labels)\n",
        "\n",
        "# # Function to process, preprocess (pad), and save the entire dataset in batches\n",
        "# def process_and_save_batches(file_path, batch_size=100000, output_dir='batches', common_size=(60, 60)):\n",
        "#     if not os.path.exists(output_dir):\n",
        "#         os.makedirs(output_dir)\n",
        "\n",
        "#     data = load_data(file_path)\n",
        "\n",
        "#     if isinstance(data, torch.utils.data.dataset.Subset):\n",
        "\n",
        "#         data_loader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
        "#         total_batches = len(data_loader)\n",
        "\n",
        "#         for i, batch_data in enumerate(data_loader):\n",
        "\n",
        "#             print(f'Starting Batch {i+1}/{total_batches}.')\n",
        "\n",
        "#             X_padded, Y_padded = preprocess_and_convert(batch_data, common_size)\n",
        "#             save_batch(X_padded, Y_padded, i, output_dir)\n",
        "#             print(f'Batch {i+1}/{total_batches} processed and saved.')\n",
        "\n",
        "#     elif isinstance(data, list):\n",
        "#         total_batches = (len(data) // batch_size) + (1 if len(data) % batch_size != 0 else 0)\n",
        "#         for i in range(total_batches):\n",
        "#             start_index = i * batch_size\n",
        "#             end_index = start_index + batch_size\n",
        "#             batch_data = data[start_index:end_index]\n",
        "\n",
        "#             X_padded, Y_padded = preprocess_and_convert(batch_data, common_size)\n",
        "#             save_batch(X_padded, Y_padded, i, output_dir)\n",
        "#             print(f'Batch {i+1}/{total_batches} processed and saved.')\n",
        "\n",
        "#     else:\n",
        "#         raise TypeError(\"Unsupported data type for batching\")\n",
        "\n",
        "\n",
        "# file_path = 'train_5M_struct.pkl'\n",
        "# batch_size = 100000\n",
        "# process_and_save_batches(file_path, batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LnluRc6ElCpc"
      },
      "outputs": [],
      "source": [
        "#  !zip -r batches.zip batches/\n",
        "#  !unzip batches.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "70tp8O5Ku9LC"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download(\"batches.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2Pa3y0ivYwr",
        "outputId": "0fd3fad1-266e-4928-8fb3-2b0e833b2555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ElU8uQqJvvYs"
      },
      "outputs": [],
      "source": [
        "# !cp -r batches/ '/content/gdrive/My Drive/'\n",
        "# !ls -lt '/content/gdrive/My Drive/'\n",
        "\n",
        "# !unzip '/content/gdrive/My Drive/batches.zip'\n",
        "\n",
        "# torch.save(model.state_dict(), 'model.pth')\n",
        "# !cp model.pth '/content/gdrive/My Drive/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DTkXl7mC_5rs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(5, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((10, 10))  # output size of 10x10\n",
        "        self.fc1 = nn.Linear(64 * 10 * 10, 512)\n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.adaptive_pool(x)  # Adaptive pooling layer\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# class StructureCNN(nn.Module):\n",
        "#     def __init__(self, num_channels, output_size):\n",
        "#         super(StructureCNN, self).__init__()\n",
        "#         self.output_size = output_size\n",
        "#         self.conv1 = nn.Conv2d(num_channels, 16, kernel_size=3, padding=1)\n",
        "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "#         self.adaptive_pool = nn.AdaptiveAvgPool2d((self.output_size, self.output_size))\n",
        "#         self.fc1 = nn.Linear(64 * self.output_size * self.output_size, 512)\n",
        "#         self.fc2 = nn.Linear(512, self.output_size * self.output_size)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.conv1(x))\n",
        "#         x = F.relu(self.conv2(x))\n",
        "#         x = F.relu(self.conv3(x))\n",
        "#         x = self.adaptive_pool(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = self.fc2(x)\n",
        "#         x = x.view(-1, self.output_size, self.output_size)\n",
        "#         x = torch.sigmoid(x)\n",
        "#         return x\n",
        "\n",
        "class StructureCNN(nn.Module):\n",
        "    def __init__(self, num_channels, output_size):\n",
        "        super(StructureCNN, self).__init__()\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Convolutional layers with batch normalization\n",
        "        self.conv1 = nn.Conv2d(num_channels, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "\n",
        "        # Pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Fully connected layers\n",
        "        reduced_size = output_size // 2**2  # Adjust based on the number of pooling layers\n",
        "        self.fc1 = nn.Linear(512 * reduced_size * reduced_size, 1024)\n",
        "        self.fc2 = nn.Linear(1024, output_size * output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "\n",
        "        # Flatten the output for the fully connected layer\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # Reshape to the output dimension and apply sigmoid activation\n",
        "        x = x.view(-1, self.output_size, self.output_size)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1ckVh-x_xz1",
        "outputId": "376251a0-5c8e-406c-e114-bbaa1378bdc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import gc\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import os\n",
        "\n",
        "# Function to load a batch from file, which includes features and labels\n",
        "def load_batch(file_path):\n",
        "    with np.load(file_path) as data:\n",
        "        return data['features'], data['labels']\n",
        "\n",
        "# Function to train the model using preprocessed batches from a directory\n",
        "def train_model_from_batches(batch_dir, model, criterion, optimizer, num_epochs=100, batch_size=128):\n",
        "    batch_files = [os.path.join(batch_dir, f) for f in os.listdir(batch_dir) if f.endswith('.npz')]\n",
        "    print(batch_files)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Starting epoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "        sum_loss = 0\n",
        "        batch_loss = 0\n",
        "        total_size = 0\n",
        "        avg_val_loss = 0\n",
        "\n",
        "        for batch_file in batch_files:\n",
        "            print(f'Loading {batch_file}')\n",
        "            features, labels = load_batch(batch_file)\n",
        "\n",
        "            # Convert numpy arrays to tensors\n",
        "            features_tensor = torch.tensor(features, dtype=torch.float32)\n",
        "            labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "            # Split the batch into training and validation sets\n",
        "            X_train, X_val, y_train, y_val = train_test_split(features_tensor, labels_tensor, test_size=0.1, random_state=42)\n",
        "\n",
        "            # Create data loaders\n",
        "            train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "            val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "            # Training loop\n",
        "            model.train()\n",
        "            for inputs, labels in train_loader:\n",
        "\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                sum_loss += loss.item()\n",
        "                batch_loss += loss.item()\n",
        "\n",
        "            total_size += len(train_loader)\n",
        "\n",
        "            # Validation loop\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item()\n",
        "                val_loss /= len(val_loader)\n",
        "\n",
        "            print(f'Epoch {epoch+1}, Batch processed, Batch Loss :{batch_loss / len(train_loader)} , Validation Loss: {val_loss:.6f}')\n",
        "            avg_val_loss += val_loss\n",
        "\n",
        "            # Free memory after processing each batch\n",
        "            del features, labels, features_tensor, labels_tensor, X_train, X_val, y_train, y_val, train_loader, val_loader\n",
        "            torch.cuda.empty_cache()  # If using CUDA\n",
        "\n",
        "        average_loss = sum_loss / total_size\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {average_loss:.6f}, Average val loss: {avg_val_loss * len(batch_files):.6f}', end='')\n",
        "\n",
        "        torch.save(model.state_dict(), 'model_new.pth')\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "batch_dir = 'batches'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = StructureCNN(num_channels=5, output_size=60).to(device)\n",
        "model.load_state_dict(torch.load('/content/gdrive/My Drive/model.pth'))\n",
        "\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
        "\n",
        "train_model_from_batches(batch_dir, model, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bDFG2zQCrHZ"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# #split the dataset into training and testing\n",
        "# X_train, X_test, y_train, y_test = train_test_split(dataset_X, structures, test_size=0.2, random_state=42)\n",
        "# X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "# #print(X_train.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTgynBYUCrHZ"
      },
      "outputs": [],
      "source": [
        "# # Pad and convert X_train and y_train to tensors\n",
        "\n",
        "# X_train_padded = [pad_structure(x, common_size, 5) for x in X_train]\n",
        "# # No padding if predicting mfe\n",
        "# y_train_padded = [pad_structure(y, common_size) for y in y_train]\n",
        "\n",
        "# X_train_tensors = [torch.tensor(x, dtype=torch.float32) for x in X_train_padded]\n",
        "# y_train_tensors = [torch.tensor(y, dtype=torch.float32) for y in y_train_padded]\n",
        "\n",
        "# # y_train_tensors = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "# dataset = [(x, y) for x, y in zip(X_train_tensors, y_train_tensors)]\n",
        "\n",
        "# X_val_padded = [pad_structure(x, common_size, 5) for x in X_val]\n",
        "# X_val_tensors = [torch.tensor(x, dtype=torch.float32) for x in X_val_padded]\n",
        "# # y_val_tensors = torch.tensor(y_val, dtype=torch.float32)\n",
        "# y_val_padded = [pad_structure(y, common_size) for y in y_val]\n",
        "# y_val_tensors = [torch.tensor(y, dtype=torch.float32) for y in y_val_padded]\n",
        "\n",
        "# val_dataset = [(x, y) for x, y in zip(X_val_tensors, y_val_tensors)]\n",
        "\n",
        "# # DataLoader setup\n",
        "# batch_size = 32\n",
        "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# # model = SimpleCNN()\n",
        "# model = StructureCNN(num_channels=5, output_size=50)\n",
        "\n",
        "# criterion = nn.BCELoss()\n",
        "# # criterion = nn.MSELoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# losses = []\n",
        "# # Training loop with validation\n",
        "# num_epochs = 100\n",
        "# for epoch in range(num_epochs):\n",
        "#     model.train()\n",
        "#     sum_loss = 0\n",
        "#     for inputs, labels in dataloader:\n",
        "#         # Forward pass\n",
        "#         outputs = model(inputs)\n",
        "#         # loss = criterion(outputs, labels.unsqueeze(1))\n",
        "#         loss = criterion(outputs, labels)\n",
        "\n",
        "#         # Backward and optimize\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         sum_loss += loss.item()\n",
        "\n",
        "#     average_loss = sum_loss / len(dataloader.dataset)\n",
        "#     print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {average_loss:.6f}', end='')\n",
        "\n",
        "#     # Validation loss calculation\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         val_loss = 0\n",
        "#         for inputs, labels in val_dataloader:\n",
        "#             outputs = model(inputs)\n",
        "#             # loss = criterion(outputs, labels.unsqueeze(1))\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             val_loss += loss.item()\n",
        "#         average_val_loss = val_loss / len(val_dataloader.dataset)\n",
        "#         print(f', Validation Loss: {average_val_loss:.6f}')\n",
        "#     losses.append((average_loss, average_val_loss))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbAkcn0_LB_7"
      },
      "outputs": [],
      "source": [
        "# model = SimpleCNN()\n",
        "\n",
        "# # Load the saved model weights\n",
        "# model.load_state_dict(torch.load('model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4il4YSZfCrHa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "model.eval()\n",
        "\n",
        "X_test_padded = [pad_structure(x, common_size, 5) for x in X_test]\n",
        "X_test_tensors = [torch.tensor(x, dtype=torch.float32) for x in X_test_padded]\n",
        "\n",
        "# No padding if predicting mfe\n",
        "y_test_padded = [pad_structure(y, common_size) for y in y_train]\n",
        "# y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "y_test_tensor = [torch.tensor(y, dtype=torch.float32) for y in y_test_padded]\n",
        "\n",
        "# DataLoader for the test set\n",
        "test_dataset = [(x, y) for x, y in zip(X_test_tensors, y_test_tensor)]\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "test_loss_sum = 0\n",
        "mae_sum = 0\n",
        "\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "# No need to track gradients for testing\n",
        "with torch.no_grad():\n",
        "    for x_tensor, y_tensor in test_dataloader:\n",
        "        output = model(x_tensor)  # x_tensor already has a batch dimension from the DataLoader\n",
        "        loss = criterion(output, y_tensor.unsqueeze(1))\n",
        "\n",
        "        test_loss_sum += loss.item()\n",
        "\n",
        "        # Calculate MAE for the batch and add to the total MAE sum\n",
        "        mae = torch.mean(torch.abs(output.squeeze() - y_tensor))\n",
        "        mae_sum += mae.item() * x_tensor.size(0)\n",
        "\n",
        "        predictions.extend(output.squeeze().tolist())  # Flatten and add to predictions list\n",
        "        actuals.extend(y_tensor.tolist())  # Flatten and add to actuals list\n",
        "\n",
        "# Calculate the average test loss\n",
        "average_test_loss = test_loss_sum / len(test_dataloader.dataset)\n",
        "average_mae = mae_sum / len(test_dataloader.dataset)\n",
        "\n",
        "print(f'Test Loss: {average_test_loss:.4f}')\n",
        "print(f'MAE: {average_mae:.4f}')\n",
        "\n",
        "# Calculate R-squared value\n",
        "r_squared = r2_score(actuals, predictions)\n",
        "print(f'R^2: {r_squared:.4f}')\n",
        "\n",
        "# Plot predictions vs actuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(actuals, predictions, alpha=0.5)\n",
        "plt.title(f'Predictions vs Actuals (R² = {r_squared:.4f})')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.grid(True)\n",
        "plt.plot([min(actuals), max(actuals)], [min(actuals), max(actuals)], 'r--')  # Diagonal line for reference\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQi8BdJk9JDM"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGoY82hjs33q"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
